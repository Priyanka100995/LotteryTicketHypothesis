import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import random
random.seed(0)
#0% model
x = [0.6666353999999988, 0.6682214999999996, 0.5465470000000003, 0.5633412999999994, 0.4970591]
avg_x = np.mean(x)
std_dev_x = np.std(x)
print(avg_x, std_dev_x)
x1 = [avg_x, avg_x, avg_x, avg_x, avg_x, avg_x, avg_x, avg_x, avg_x, avg_x, avg_x, avg_x, avg_x]
#lth pruned models
z1 = [0.5589223000000008, 0.4701958000000004, 0.5016821999999999, 0.4358765, 0.4296742, 0.42130519999999994, 0.4674863, 0.5100369000000002, 0.45769230000000016, 0.4392482000000002, 0.47356500000000024, 0.4421987999999999, 0.4619650000000002]
z2 = [0.4568304999999997, 0.4463702999999999, 0.4519582000000004, 0.46839920000000035,  0.5273629999999998, 0.5008333,  0.5917240000000001, 0.5345301999999998, 0.5415280000000005,  0.5179499999999999, 0.5033088000000001, 0.5295152000000001, 0.5198655000000008]
z3 = [0.4617933999999999, 0.5276553000000006, 0.5449441000000004, 0.6870757000000003, 0.5099187000000001, 0.4875797999999998, 0.5311767000000005, 0.5204779999999998, 0.5856718999999995, 0.4852432000000002, 0.4964038000000004, 0.4714394999999998, 0.5871616]
z4 = [0.45355670000000003, 0.44187580000000004, 0.4456410000000002, 0.4514090999999998, 0.5055477000000002, 0.4942481999999999, 0.49583469999999963, 0.4899439000000001, 0.47725410000000057,  0.4733488000000001, 0.4702890000000002,0.47104999999999997, 0.4692177000000002]
z5 = [ 0.4431479000000005, 0.48648559999999996, 0.4939694999999995, 0.4627047999999996, 0.48938840000000017, 0.5182844000000006,  0.47347560000000044, 0.4619043999999999, 0.4757560999999999,  0.4861761999999996,  0.4672896999999998, 0.48168840000000035,  0.4615209]
z = np.asarray([z1, z2, z3, z4, z5])
df = pd.DataFrame({"z1" : [0.5589223000000008, 0.4701958000000004, 0.5016821999999999, 0.4358765, 0.4296742, 0.42130519999999994, 0.4674863, 0.5100369000000002, 0.45769230000000016, 0.4392482000000002, 0.47356500000000024, 0.4421987999999999, 0.4619650000000002],
"z2" : [0.4568304999999997, 0.4463702999999999, 0.4519582000000004, 0.46839920000000035,  0.5273629999999998, 0.5008333,  0.5917240000000001, 0.5345301999999998, 0.5415280000000005,  0.5179499999999999, 0.5033088000000001, 0.5295152000000001, 0.5198655000000008],
"z3" : [0.4617933999999999, 0.5276553000000006, 0.5449441000000004, 0.6870757000000003, 0.5099187000000001, 0.4875797999999998, 0.5311767000000005, 0.5204779999999998, 0.5856718999999995, 0.4852432000000002, 0.4964038000000004, 0.4714394999999998, 0.5871616],
"z4" : [0.45355670000000003, 0.44187580000000004, 0.4456410000000002, 0.4514090999999998, 0.5055477000000002, 0.4942481999999999, 0.49583469999999963, 0.4899439000000001, 0.47725410000000057,  0.4733488000000001, 0.4702890000000002,0.47104999999999997, 0.4692177000000002],
"z5" : [ 0.4431479000000005, 0.48648559999999996, 0.4939694999999995, 0.4627047999999996, 0.48938840000000017, 0.5182844000000006,  0.47347560000000044, 0.4619043999999999, 0.4757560999999999,  0.4861761999999996,  0.4672896999999998, 0.48168840000000035,  0.4615209]})

std_dev_lth = np.std(z)
#print(std_dev_lth)
#Mean
Mean_lth = df.mean(axis = 1)
print('Mean', Mean_lth)


# structured pruned models
y1 = [0.4820422, 0.372106799999999, 0.3662998000000002, 0.36062020000000006, 0.3634729000000001, 0.38987190000000016, 0.36978389999999983, 0.3832084, 0.36549730000000036, 0.3620681999999995, 0.3341604, 0.3054836999999999, 0.29065490000000027]
y2 = [0.4341394000000003, 0.4134494999999996, 0.41397070000000014, 0.4020562999999999, 0.4260507000000002, 0.43809790000000026, 0.40814220000000034, 0.39806089999999994, 0.39886269999999957,  0.3802341999999994, 0.3865463, 0.3207348999999997, 0.3059067]
y3 = [0.4212900000000004, 0.42621620000000027, 0.41394030000000015, 0.3993500000000001, 0.4322461000000004,  0.43527050000000056, 0.40124280000000034, 0.3834909999999998, 0.3854766000000005, 0.3958925, 0.3972666, 0.3455117999999997, 0.3127627999999998]
y4= [0.4161862999999997, 0.42983689999999974, 0.41873700000000014, 0.40380079999999996, 0.43642679999999956, 0.44727279999999947, 0.39453950000000004, 0.39780789999999966, 0.38323790000000013, 0.3970478000000002, 0.37141300000000044, 0.3450319999999998, 0.31337490000000034]
y5= [0.4185985999999997, 0.42190360000000027, 0.4189942000000002, 0.4118175000000006, 0.4238344000000005,  0.4267493, 0.42008180000000017,  0.3895175000000002, 0.38207570000000013, 0.3904112000000004, 0.39317780000000013, 0.35424969999999956,  0.31543290000000024]
y = np.asarray([y1, y2, y3, y4, y5])
df1 = pd.DataFrame({"y1" : [0.4820422, 0.372106799999999, 0.3662998000000002, 0.36062020000000006, 0.3634729000000001, 0.38987190000000016, 0.36978389999999983, 0.3832084, 0.36549730000000036, 0.3620681999999995, 0.3341604, 0.3054836999999999, 0.29065490000000027],
"y2" : [0.4341394000000003, 0.4134494999999996, 0.41397070000000014, 0.4020562999999999, 0.4260507000000002, 0.43809790000000026, 0.40814220000000034, 0.39806089999999994, 0.39886269999999957,  0.3802341999999994, 0.3865463, 0.3207348999999997, 0.3059067],
"y2" : [0.4212900000000004, 0.42621620000000027, 0.41394030000000015, 0.3993500000000001, 0.4322461000000004,  0.43527050000000056, 0.40124280000000034, 0.3834909999999998, 0.3854766000000005, 0.3958925, 0.3972666, 0.3455117999999997, 0.3127627999999998],
"y4" : [0.4161862999999997, 0.42983689999999974, 0.41873700000000014, 0.40380079999999996, 0.43642679999999956, 0.44727279999999947, 0.39453950000000004, 0.39780789999999966, 0.38323790000000013, 0.3970478000000002, 0.37141300000000044, 0.3450319999999998, 0.31337490000000034],
"y5" : [0.4185985999999997, 0.42190360000000027, 0.4189942000000002, 0.4118175000000006, 0.4238344000000005,  0.4267493, 0.42008180000000017,  0.3895175000000002, 0.38207570000000013, 0.3904112000000004, 0.39317780000000013, 0.35424969999999956,  0.31543290000000024]})
#standard deviation
std_dev = np.std(y)
#print(std_dev)
#Mean
Mean = df1.mean(axis = 1)
print('Mean keras', Mean)


P = pd.DataFrame({'Perc' : [0.474850, 0.434529, 0.474517, 0.412516, 0.487639, 0.404493, 0.501093, 0.393897, 0.492378, 0.413995,
                            0.484450, 0.424791, 0.511939, 0.396412, 0.503379, 0.388506, 0.507580, 0.379072, 0.480393, 0.386355,
                            0.482171, 0.374004,  0.479178, 0.337569, 0.499946, 0.308056]})


Percent = P.pct_change(axis=0, periods=1)
print(abs(Percent)*100)
'''''
my_xticks = ['0.00 ', '19.97 ', '35.94 ', '46.97 ',  '58.95 ', '67.13 ', '74.15 ', '80.21 ', '91.66 ', '94.09 ', '96.95 ', '98.80 ', '99.40 ']
plt.tick_params(axis='x', which='major', labelsize=8)
plt.ylim(0.25, 0.70)
plt.xlabel ('Models with Percentages of weights pruned (%)')
plt.ylabel ('Inference Time (s)')
plt.plot(my_xticks, x1, label='LTH Pruned Models', color='blue', marker='*', markersize=4 )
plt.fill_between(my_xticks, avg_x-std_dev_x, avg_x+std_dev_x,color='blue', alpha=.2)
plt.plot(my_xticks, Mean_lth, label='LTH Pruned Models', color='orange', marker='*', markersize=4 )
plt.fill_between(my_xticks, Mean_lth-std_dev_lth, Mean_lth+std_dev_lth,color='orange', alpha=.2)
#plt.plot(my_xticks, Mean, label='Keras Surgeon Pruned Models', color='magenta', marker='*', markersize=4 )
#plt.fill_between(my_xticks, Mean-std_dev, Mean+std_dev,color='magenta', alpha=.2)
#plt.title('Pruned Models vs Inference Time')
plt.grid()
plt.show()

x = [0.00, 19.97, 35.94, 46.97,  58.95, 67.13, 74.15, 80.21, 91.66, 94.09, 96.95, 98.80, 99.40 ]
#infernece time on NVIDIA#y = [0.580260, 0.583279, 0.560138, 0.596135, 0.579221, 0.450629, 0.622064,  0.577368, 0.623445, 0.455751]
#infernece time LTH pruned models
y = [0.5589223000000008, 0.4701958000000004, 0.5016821999999999, 0.4358765, 0.4296742, 0.42130519999999994, 0.4674863, 0.5100369000000002, 0.45769230000000016, 0.4392482000000002, 0.47356500000000024, 0.4421987999999999, 0.4619650000000002]
my_xticks = ['0.00 ', '19.97 ', '35.94 ', '46.97 ',  '58.95 ', '67.13 ', '74.15 ', '80.21 ', '91.66 ', '94.09 ', '96.95 ', '98.80 ', '99.40 ']
plt.figure()

plt.ylim(0.25, 0.60)
plt.xlabel ('Models with Percentages of weights pruned (%)')
plt.ylabel ('Inference Time (s)')
plt.tick_params(axis='x', which='major', labelsize=8)
plt.plot(my_xticks, y, color='red', marker='*',  markersize=4 ,label= 'Epochs vs Percentags of weights pruned')
plt.plot(my_xticks, y1, color='green', marker='*', markersize=4 ,label='Keras Surgeon Pruned Models')
plt.title('Pruned Models vs Inference Time')
plt.grid()

#plt.savefig('Pruned Models vs Inference Time 18_05_21')
plt.show()


x = [0.00, 19.97, 35.94, 46.97,  58.95, 67.13, 74.15, 80.21, 91.66, 94.09, 96.95, 98.80, 99.40 ]
y = [7943, 7943, 7943, 7943, 7943, 7943, 7943, 7943, 7943, 7943, 7943, 7943, 7943]
y2 =[5470, 5348, 5406, 5142, 5468, 5480, 5348, 5220, 4229, 3733, 2723, 653, 182]
my_xticks1 = ['0.00 ', '19.97 ', '35.94 ', '46.97 ',  '58.95 ', '67.13 ', '74.15 ', '80.21 ', '91.66 ', '94.09 ', '96.95 ', '98.80 ', '99.40 ']
plt.figure()

plt.xlabel('Models with Percentages of weights pruned (%)')
plt.ylabel('Size of models (kb)')
plt.tick_params(axis='x', which='major', labelsize=8)
plt.plot(my_xticks1, y, label='LTH Pruned models', color='red')
plt.plot(my_xticks1, y2, label='Keras surgeon Pruned models', color='green')
plt.grid()
plt.show()

x = [0.00, 19.97, 35.94, 46.97,  58.95, 67.13, 74.15, 80.21, 91.66, 94.09, 96.95, 98.80, 99.40 ]
#infernece time on NVIDIA#
y = [0.5589223000000008, 0.4701958000000004, 0.5016821999999999, 0.4358765, 0.4296742, 0.42130519999999994, 0.4674863, 0.5100369000000002, 0.45769230000000016, 0.4392482000000002, 0.47356500000000024, 0.4421987999999999, 0.4619650000000002]
my_xticks = ['0.00 ', '19.97 ', '35.94 ', '46.97 ',  '58.95 ', '67.13 ', '74.15 ', '80.21 ', '91.66 ', '94.09 ', '96.95 ', '98.80 ', '99.40 ']
plt.figure()
plt.ylim(0.25, 0.60)

plt.xlabel ('Models with Percentages of weights pruned (%)')
plt.ylabel ('Inference Time (s)')
plt.tick_params(axis='x', which='major', labelsize=8)
plt.plot(my_xticks, y, label= 'Epochs vs Percentags of weights pruned', color='red', marker='*',  markersize=4)
plt.title('Pruned Models vs Inference Time')
plt.grid()
plt.show()
#infernece time LTH pruned models
'''''